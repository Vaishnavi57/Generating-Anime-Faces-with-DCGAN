{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N0JlbhVgeoH4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\", color_codes=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Dense, Flatten, Conv2DTranspose,\n",
        "    Reshape, BatchNormalization, Dropout, Input, ReLU, LeakyReLU\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9km5b7jNjkqJ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/archive (3).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('anime_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LvandikfMDs",
        "outputId": "3f03cdb4-f24e-4cb1-e6ed-0ffad1851331"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 256, 256\n",
        "batchsize = 32\n",
        "\n",
        "train = keras. utils.image_dataset_from_directory(\n",
        "    directory='/content/anime_dataset',\n",
        "    batch_size = batchsize,\n",
        "    image_size = (img_width, img_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "v7C_wTsTkLzL",
        "outputId": "3038fae2-327d-44af-ac54-05b3ce89d50d"
      },
      "outputs": [],
      "source": [
        "iterator = iter(train)\n",
        "images, labels = next(iterator)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 6))  # 1 row, 4 columns\n",
        "for i in range(4):\n",
        "    axes[i].imshow(images[i].numpy().astype(\"uint8\"))  # convert to uint8 for plotting\n",
        "    axes[i].axis(\"off\")                               # hide axes\n",
        "    axes[i].set_title(str(labels[i].numpy()))         # show label as title\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0057LdZ1kaGF",
        "outputId": "c92fc686-b2a1-4c4a-c790-38374e281724"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset folder\n",
        "dataset_dir = '/content/anime_dataset'\n",
        "\n",
        "# Create a data generator with rescaling and horizontal flipping\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,       # normalize pixel values to [0,1]\n",
        "    horizontal_flip=True  # randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Load images from the directory as batches\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=dataset_dir,\n",
        "    target_size=(64, 64),  # resize images\n",
        "    batch_size=batchsize,\n",
        "    class_mode=None         # no labels since this is unsupervised / DCGAN\n",
        ")\n",
        "\n",
        "# Inspect the first batch of images\n",
        "images_batch = next(train_generator)\n",
        "print(\"Batch shape:\", images_batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JCnTt3qplAXR",
        "outputId": "77032bb7-77f6-4b6a-b92f-3a4d2b3b19df"
      },
      "outputs": [],
      "source": [
        "# Kernel initializer\n",
        "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "latent_dim = 300  # Dimension of random noise input\n",
        "\n",
        "def build_generator(latent_dim=latent_dim):\n",
        "    \"\"\"\n",
        "    Builds the Generator model for DCGAN.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential(name=\"Generator\")\n",
        "\n",
        "    # Dense layer to project random noise\n",
        "    model.add(keras.layers.Dense(8 * 8 * 512, input_dim=latent_dim))\n",
        "    model.add(keras.layers.ReLU())\n",
        "\n",
        "    # Reshape to 3D tensor (8x8x512)\n",
        "    model.add(keras.layers.Reshape((8, 8, 512)))\n",
        "\n",
        "    # Upsampling layers\n",
        "    model.add(keras.layers.Conv2DTranspose(\n",
        "        256, (4, 4), strides=(2, 2),\n",
        "        padding='same', kernel_initializer=kernel_init, activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.Conv2DTranspose(\n",
        "        128, (4, 4), strides=(2, 2),\n",
        "        padding='same', kernel_initializer=kernel_init, activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.Conv2DTranspose(\n",
        "        64, (4, 4), strides=(2, 2),\n",
        "        padding='same', kernel_initializer=kernel_init, activation='relu'\n",
        "    ))\n",
        "\n",
        "    # Output layer (RGB image)\n",
        "    model.add(keras.layers.Conv2D(3, (4, 4), padding='same', activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate and summarize\n",
        "generator = build_generator()\n",
        "generator.summary()\n",
        "\n",
        "# Visualize the model (optional)\n",
        "keras.utils.plot_model(generator, show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mZTg6UsDmf1b",
        "outputId": "d64d42d9-5e2a-481b-a81a-6d72f82f00cb"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(input_shape=(64, 64, 3)):\n",
        "    \"\"\"\n",
        "    Builds the Discriminator model for DCGAN.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential(name=\"Discriminator\")\n",
        "\n",
        "    # Convolutional layers with LeakyReLU activations\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), input_shape=input_shape))\n",
        "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3)))\n",
        "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(256, (3, 3)))\n",
        "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten and fully connected layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256))\n",
        "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate and summarize\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n",
        "\n",
        "# Visualize discriminator architecture (optional)\n",
        "keras.utils.plot_model(discriminator, show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7CSEooIQm3Zc"
      },
      "outputs": [],
      "source": [
        "class DCGAN(keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim=latent_dim):\n",
        "        super(DCGAN, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Metrics to track losses\n",
        "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
        "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # List of metrics to reset at the start of each epoch\n",
        "        return [self.g_loss_metric, self.d_loss_metric]\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
        "        super(DCGAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        # Generate random noise\n",
        "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # -------------------------------\n",
        "        # Train Discriminator\n",
        "        # -------------------------------\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Discriminator on real images\n",
        "            pred_real = self.discriminator(real_images, training=True)\n",
        "            real_labels = tf.ones((batch_size, 1))\n",
        "            # Label smoothing\n",
        "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n",
        "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
        "\n",
        "            # Discriminator on fake images\n",
        "            fake_images = self.generator(random_noise, training=True)\n",
        "            pred_fake = self.discriminator(fake_images, training=True)\n",
        "            fake_labels = tf.zeros((batch_size, 1))\n",
        "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "\n",
        "        # Compute and apply gradients for discriminator\n",
        "        d_gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        # -------------------------------\n",
        "        # Train Generator\n",
        "        # -------------------------------\n",
        "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_noise, training=True)\n",
        "            pred_fake = self.discriminator(fake_images, training=True)\n",
        "            # Generator wants discriminator to classify fakes as real\n",
        "            g_loss = self.loss_fn(tf.ones((batch_size, 1)), pred_fake)\n",
        "\n",
        "        # Compute and apply gradients for generator\n",
        "        g_gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {'d_loss': self.d_loss_metric.result(), 'g_loss': self.g_loss_metric.result()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BeeT4q29nBXh"
      },
      "outputs": [],
      "source": [
        "class DCGANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_imgs=25, latent_dim=latent_dim):\n",
        "        super(DCGANMonitor, self).__init__()\n",
        "        self.num_imgs = num_imgs\n",
        "        self.latent_dim = latent_dim\n",
        "        # Pre-generate random noise for monitoring\n",
        "        self.fixed_noise = tf.random.normal([self.num_imgs, self.latent_dim])\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Generate images from fixed noise\n",
        "        generated_images = self.model.generator(self.fixed_noise, training=False)\n",
        "\n",
        "        # Scale images from [0,1] to [0,255] for visualization\n",
        "        generated_images = tf.clip_by_value(generated_images * 255, 0, 255)\n",
        "        generated_images = generated_images.numpy().astype(\"uint8\")\n",
        "\n",
        "        # Optional: display a grid of generated images\n",
        "        import matplotlib.pyplot as plt\n",
        "        fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
        "        idx = 0\n",
        "        for i in range(5):\n",
        "            for j in range(5):\n",
        "                axes[i, j].imshow(generated_images[idx])\n",
        "                axes[i, j].axis('off')\n",
        "                idx += 1\n",
        "        plt.suptitle(f\"Epoch {epoch+1}\")\n",
        "        plt.show()\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        # Save the generator model after training\n",
        "        self.model.generator.save('DCGAN_Generator.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "D13AVD9FnDmB",
        "outputId": "985ba815-d759-491d-e55b-be1e3a59146d"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "lr_g =0.0003\n",
        "lr_d = 0.0001\n",
        "beta = 0.5\n",
        "latent_dim = 300\n",
        "\n",
        "dcgan = DCGAN(generator=generator, discriminator=discriminator, latent_dim = latent_dim )\n",
        "dcgan.compile(g_optimizer = Adam (learning_rate= lr_g, beta_1= beta), d_optimizer= Adam (learning_rate = lr_g , beta_1= beta), loss_fn = BinaryCrossentropy())\n",
        "\n",
        "# Fit the model and save the history\n",
        "history = dcgan.fit(train_generator, epochs=epochs, callbacks=[DCGANMonitor()])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
